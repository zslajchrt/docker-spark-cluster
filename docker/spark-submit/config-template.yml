default:
  # local-only configuration
  spark.env.SPARK_LOCAL_IP.local: 127.0.0.1

  # include the embedded csv package for spark 1.x
  sparklyr.connect.csv.embedded: "^1.*"

  # Enable Hive support by default.
  spark.sql.catalogImplementation: "hive"

  # default spark packages to load
  # sparklyr.defaultPackages:

  # command line arguments to spark-shell
  # sparklyr.shell.*

  spark.executor.memory: 4G

  #sparklyr.shell.conf: "spark.executor.extraJavaOptions=\"-Dcom.sun.management.jmxremote.port=9010 -Dcom.sun.management.jmxremote.rmi.port=9011 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.local.only=false\""
  sparklyr.shell.conf: ["spark.executor.extraJavaOptions=\"-Dcom.sun.management.jmxremote.port=9010 -Dcom.sun.management.jmxremote.rmi.port=9011 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.local.only=false\"", "spark.driver.extraJavaOptions=\"-Dcom.sun.management.jmxremote.port=9010 -Dcom.sun.management.jmxremote.rmi.port=9011 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.local.only=false\""]
